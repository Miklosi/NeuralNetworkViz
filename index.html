<!DOCTYPE html>
<meta charset="utf-8">
<meta http-equiv="Access-Control-Allow-Origin" content="*"/>

<style>

svg {
  /*position: absolute;*/
}

g.node {
  stroke: #fff;
  stroke-width: 1.5px;
}

line.link {
  stroke: #bdbdbd; /*#999;*/
  stroke-opacity: .6;
}

.d3-tip {
    line-height: 1;
    color: black;
    font-family: Arial;
    text-align: center;
}

.g-premium circle, circle.premium {
    fill: #00a3e0;
}
.g-claim circle, circle.claim {
    fill: #e4002b;

}

line.divider {
    stroke: #000; /*#666;*/
    stroke-width: 1;
}

circle.filler.outline {
    fill: #000;
    stroke: #000;
    stroke-width: 1.5;
}

</style>
<script src="http://d3js.org/d3.v3.min.js"></script>
<script type='text/javascript' src="http://labratrevenge.com/d3-tip/javascripts/d3.tip.v0.6.3.js"> </script>

<script type="text/javascript" src='https://cdnjs.cloudflare.com/ajax/libs/mathjs/1.7.0/math.js'></script>


<body>

  <div id="netoworkGraphContainer">
      
  </div>
  
  <div id="imageGenerator">
  </div>

<script>



var training_data = [];
var test_data = [];


function updateImage(dataRow) {

  var imgSVG = d3.select("#imageGenerator svg g");

  //data join
  var rect = imgSVG.selectAll('rect')
                   .data(dataRow.values);

  //note: assume square, so image is dimension*dimension
  var dimension = math.sqrt(dataRow.values.length);
  var pixelDimensions = 10;

  //update old elements as needed [only if enter().append("rect") is removed]

  function updatePixels(elem) {
    elem.attr({
    //rect.enter().append("rect")
        //.attr({
          width: pixelDimensions,
          height: pixelDimensions,
          x: function(d, i) {
            return pixelDimensions * parseInt(i % dimension);
          },
          y: function(d, i) {
            return pixelDimensions * parseInt(i / dimension);
          }
        }).style({
          fill: function (d,i) {
            return "rgb(" + d + "," + d + "," + d + ")";
          }
        });
  }

  updatePixels(rect);
  
  updatePixels(rect.enter().append("rect"));
    
  rect.exit().remove();

}



//d3.csv("./data/mnist_train_sample.csv", function(data) {
d3.text("./data/mnist_train_sample.csv", function(text) {
                      training_data = d3.csv.parseRows(text)
                                        .map(function(row) {
                                          return {
                                            result: +row.slice(0,1),
                                            values: row.slice(1).map(function(value) { return +value; })
                                          };
                                        });

                      var svg = d3.select("#imageGenerator")
                                  .append("svg")
                                  .attr({
                                    width: 280,
                                    height: 280
                                  })
                                  .append("g");

                      updateImage(training_data[0]);

                      //readyCheck("mnist_train_sample.csv");
                    });


//var readyFiles = {'mnist_train_sample.csv': false, 'mnist_train_sample.csv': false};
//function readyCheck(filename) {
  //readyFiles[filename] = true;
//
  //if (readyFiles['mnist_train_sample']==true && readyFiles['mnist_train_sample']==true) {
    ////...begin drawing visualization...
//
  //}
//}






  //TODO: test self.backprop & write self.evaluate fns
    

  var training = {
    inputs: [
      math.matrix([[0],[0]]),
      math.matrix([[0],[1]]),
      math.matrix([[1],[0]]),
      math.matrix([[1],[1]])
    ],
    targets: [
      [0],
      [0],
      [0],
      [1]
    ]    
  };
  training = d3.zip(training.inputs, training.targets);


var Network = function(sizes) {
  
  var self = this;

  Network.prototype.init = function() {
    self.num_layers = sizes.length;
    self.sizes = sizes;
    
      //sizes: [4,5,6,7] //no. neurons at each layer
    /*self.biases = sizes.slice(1, sizes.length)
                       .map(function(x, i) { 
                          return math.matrix(math.random([x]));
                        });


    self.weights = sizes.slice(1, sizes.length)
                        .map(function(x, i) {
                          return math.matrix(math.random([x,sizes[i]]));
                        });  */
    
    //TEST DATA - replace math.matrix with array keyword in IPython
    //https://www.pythonanywhere.com/try-ipython/
    self.biases = [
        math.matrix([[ 0.28025098],[-0.95476184],[-0.19975343]])
        , 
        math.matrix([[-0.23912252]])
    ];

    self.weights = [
        math.matrix([[-0.22562396,  0.15815544],
                     [-1.33556601, -1.75698585],
                     [-0.6862575 , -0.28076993]]),
        math.matrix([[ 0.32204661, -1.3949658 ,  0.11311598]])
    ];

  };



  //eg.: [[1],[1]]
  Network.prototype.feedForward = function(a) { //a: inputs
    for (var i = 0; i < self.weights.length; i++) {
      a = sigmoid_vec(
            math.add(
              math.multiply(self.weights[i], a), 
              self.biases[i]
            )
          ); 
    }
    return a;
  };

  //https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network.py

  //"training_data": list of tuples "(x, y)" representing the training inputs & desired outputs. 

  Network.prototype.SGD = function(training_data, epochs, mini_batch_size, eta) {//,test_data=None
    var n = training_data.length;


    for (var j = 1; j <= epochs; j++) {
      var epoch_training_data = d3.shuffle(training_data);

      var mini_batches = [];
      for (var k=0; k < n; k += mini_batch_size) {
        mini_batches.push(epoch_training_data.slice(k, k+mini_batch_size));
      }

      for (var m = 0; m < mini_batches.length; m++) {
        self.update_mini_batch(mini_batches[m], eta);
      }

      console.log("Epoch " + j + " complete");
    }

  };

  //mini_batch: array of tuples (x,y) : (training_input, target)
  Network.prototype.update_mini_batch = function(mini_batch, eta) {
    console.log(math.format(mini_batch));

    var nabla_b = self.biases
                      .map(function(x) { 
                        return math.matrix(math.zeros(x.size()))
                      });
    var nabla_w = self.weights
                      .map(function(x) { 
                        return math.matrix(math.zeros(x.size())) 
                      });

    for (var m = 0; m < mini_batch.length; m++) {
      var x = mini_batch[m][0], 
          y = mini_batch[m][1]; 

      //var backprop_result = self.backprop(x, y);
      //var delta_nabla_b = backprop_result[0],
      //    delta_nabla_w = backprop_result[1];

      //temp solution until self.backprop() is written!!
      var delta_nabla_b = self.biases.map(function(x) { return math.matrix(math.ones(x.size())) });
      var delta_nabla_w = self.weights.map(function(x) { return math.matrix(math.ones(x.size())) });
   
      nabla_b = nabla_b.map(function(x, i) { return math.add(nabla_b[i], delta_nabla_b[i]) });
      nabla_w = nabla_w.map(function(x, i) { return math.add(nabla_w[i], delta_nabla_w[i]) });
      

      self.biases = d3.zip(self.biases, nabla_b)
                      .map(function(x, i) {
                        var b = x[0], nb = x[1];
                        return math.subtract(b, math.multiply(nb, parseFloat(eta)/mini_batch.length));
                      });

      self.weights = d3.zip(self.weights, nabla_w)
                       .map(function(x, i) {
                         var w = x[0], nw = x[1];
                         return math.subtract(w, math.multiply(nw, parseFloat(eta)/mini_batch.length));
                       });
    }
  };

  Network.prototype.backprop = function(x, y) {
    
    var nabla_b = self.biases
                      .map(function(x) { 
                        return math.matrix(math.zeros(x.size()))
                      });
    var nabla_w = self.weights
                      .map(function(x) { 
                        return math.matrix(math.zeros(x.size())) 
                      });

    //feed-foward
    var activation = x,
        activations = [x],
        zs = [];

    for (var k = 0; k < self.biases.length; k++) {
        var w = self.weights[k], 
            b = self.biases[k];
        var z = math.add(math.multiply(w, activation), b);

        zs.push(z);
        activations.push(sigmoid_vec(z));
    }

    //backward-pass
        //delta = self.cost_derivative(activations[-1], y) * \ sigmoid_prime_vec(zs[-1])
    var delta = self.cost_derivative(activations[activations.length-1], y) * 
                  sigmoid_prime_vec(zs[zs.length-1]);
    nabla_b[nabla_b.length-1] = delta;
    nabla_w[nabla_w.length-1] = math.multiply(delta, math.transpose(activations[activations.length-2]));

    for (var l = 2; l < self.num_layers; l++) {
      var z = zs[zs.length-l];
      var spv = sigmoid_prime_vec(z);
      
      //delta = np.dot(self.weights[-l+1].transpose(), delta) * spv
      delta = math.multiply(math.multiply(math.transpose(activations[activations.length-l+1]), delta), spv)

      nabla_b[nabla_b.length-l] = delta; //nabla_b[-l] = delta

                                //nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())
      nabla_w[nabla_w.length-l] = math.multiply(delta, math.transpose(activations[activations.length-l-1]));
      
    }

    return [nabla_b, nabla_w];
  };

  Network.prototype.evaluate = function(test_data) {
      //return (for test_data) the no. cases where self.feed_forward(inputs) == test_data.outputs

      
      
  };

  Network.prototype.cost_derivative = function(output_activations, y) {
    return math.subtract(output_activations, y);
  };





//math.transpose(math.matrix([[0,1]]))




  /*
function mlpFwd(inputs) {//

  //hidden activations (hidden: 4r*3c)
  hidden = math.multiply(inputs, weights1);//
     //math.divide(1, math.add(math.exp(math.multiply(-1,hidden)),1))
  hidden = hidden.map(function (value) {      
                         return 1/(1 + Math.exp(-1*value));
                     });
  hidden = addBiasColumnTo(hidden);

  //output activations 4r 1c
  var activations = math.multiply(hidden, weights2);

  switch (outputType) 
  {
    case 'linear':   
      return linearError(activations);
    case 'logistic':   
      return logisticError(activations);
    case 'softmax':   
      return softmaxError(activations);
  }


}

  */








/*
  Network.prototype.method_name = function() {
    console.log('size:' + this.sizes);
  };   
*/



  this.init();
};


var sigmoid = function(z) { return 1.0/(1.0 + Math.exp(-z)) };
var sigmoid_prime = function(z) { return this.sigmoid(z)*(1-sigmoid(z)) };

var sigmoid_vec = function(v) {return v.map(sigmoid) };
var sigmoid_prime_vec = function(v) {return v.map(sigmoid_prime) };


















//math.matrix([[0, 1], [2, 3], [4, 5]]); 



var inputDimensions = 2, //nIn
    outputDimensions = 1, //nOut
    BIAS_VALUE = -1, //constant value for bias
    TRAINING_EPOCHS = 5001; //#1001, 5001

var inputs = math.matrix([
                   [0, 0],
                   [0, 1],
                   [1, 0],
                   [1, 1]
            ]),
    targets = math.matrix([
                   [0],
                   [1],
                   [1],
                   [1]
            ]);

var nData = inputs.size()[0], //4 in this case
    nHidden = 2, //no. hidden neurons
    learningrate = 0.25,
    momentum = 0.9,
    hidden = math.ones(nHidden+1,nData),
    outputType = "linear";

var initialiseFn = function(x) { return (Math.random() -.5) * 2/Math.sqrt(inputDimensions); };

                //weights from inputs to hidden neurons
var weights1 = math.ones(inputDimensions+1, nHidden)
                   .map(initialiseFn), 

                //weights from hidden neurons to outputs
    weights2 = math.ones(nHidden+1, outputDimensions)
                   .map(initialiseFn);


var addBiasColumnTo = function(matrix) {
    var nRows = matrix.size()[0], 
        nCols = matrix.size()[1];

    return matrix.resize([nRows, nCols+1])
                 .map(function(x, i) { 
                   return i[1] == nCols ? BIAS_VALUE : x; 
                 });
}


inputs = addBiasColumnTo(inputs);


function linearError(activations) {
  return math.dotMultiply(
                math.subtract(activations, targets),
                1/nData);
}

function logisticError(activations) {
  return math.dotMultiply.call(
                  math.subtract(activations, targets),
                  activations,
                  math.subtract(1, activations)
                );
}

function softmaxError(activations) {
  return math.dotMultiply.call(
                  math.subtract(activations, targets),
                  math.subtract(
                        activations,
                        math.dotMultiply.call(activations, activations, -1)
                  ),
                  1/nData
                );
}





function mlpFwd(inputs) {//

  //hidden activations (hidden: 4r*3c)
  hidden = math.multiply(inputs, weights1);//
     //math.divide(1, math.add(math.exp(math.multiply(-1,hidden)),1))
  hidden = hidden.map(function (value) {      
                         return 1/(1 + Math.exp(-1*value));
                     });
  hidden = addBiasColumnTo(hidden);

  //output activations 4r 1c
  var activations = math.multiply(hidden, weights2);

  switch (outputType) 
  {
    case 'linear':   
      return linearError(activations);
    case 'logistic':   
      return logisticError(activations);
    case 'softmax':   
      return softmaxError(activations);
  }


}



var updateW1 = math.zeros(weights1.size()[0],weights1.size()[1]),
    updateW2 = math.zeros(weights2.size()[0],weights2.size()[1]),
    activations = null;


for (var i=0; i<TRAINING_EPOCHS; i++) {
  
  //feed forward the inputs to get the current outputs
  activations = mlpFwd(inputs)

  //error <- 0.5 * sum((activations-targets)^2)
  //#if(error %% 100 == 0) break
  
  //amount to change weights2 by
  switch (outputType) 
  {
    case 'linear':   
      delta0 = linearError(activations);
      break;
    case 'logistic':   
      delta0 = logisticError(activations);
      break;
    case 'softmax':   
      delta0 = softmaxError(activations);
      break;
  }

  //amount to change weights1 by
    //-hidden * (1-hidden) * deltaO %*% t(weights2)
  deltaH = math.dotMultiply.call(
                    math.multiply(hidden, -1), 
                    math.subtract(1, hidden),
                    math.multiply(delta0, math.transpose(weights2))              
            );
    
  
  //updateW1 <- 
    //learningrate * 
    //(t(inputs) %*% deltaH[,-ncol(deltaH)]) + 
    //(momentum * updateW1)
  updateW1 = math.multiply(
                learningrate,
                math.add(
                  math.multiply(
                    math.transpose(inputs),
                    deltaH.resize([deltaH.size()[0],deltaH.size()[1]-1])
                  ),
                  math.multiply(momentum, updateW1)
                )
             );

  //updateW2 <- 
    //learningrate * 
    //(t(hidden) %*% deltaO) + 
    //(momentum * updateW2)
  updateW2 = math.multiply(
                learningrate,
                math.add(
                  math.multiply(
                    math.transpose(hidden),
                    delta0
                  ),
                  math.multiply(momentum, updateW2)
                )
             );


  weights1 = math.subtract(weights1, updateW1);
  weights2 = math.subtract(weights2, updateW2);
}

//
//testing: (if working output = target)
//mlpfwd(inputs)
//ifelse(mlpfwd(inputs) > .5,1,0)
console.log(
    math.format(
      activations.map(function(x) { 
                        return x > 0 ? 1 : 0 }), 
      1)
    );



hidden.map(function(x, i) { 
  return i.toString().replace(",","") 
})._data



var width = 500,
    height = 500,
    minCircleRadius = 0;


var graphMLPData = {
  nodes: [
    { name: "in1", group: 0, size: 25, x: width/4, y: height/3, fixed: true },
    { name: "in2", group: 1, size: 25, x: width/4, y: 2*height/3, fixed: true },


      { name: "biashidden1", group: 2, size: 25, x: 3*width/8, y: height/6, fixed: true },  
    { name: "hidden1", group: 3, size: 25, x: width/2, y: height/3, fixed: true },
    { name: "hidden2", group: 4, size: 25, x: width/2, y: 2*height/3, fixed: true },

      { name: "biasOut", group: 5, size: 25, x: 5*width/8, y: height/6, fixed: true },  
    { name: "out1", group: 6, size: 25, x: 3*width/4, y: height/2, fixed: true }
  ],
  links: [  //source & target: index in nodes array,   value:  strength of link 
      
    { source: 0, target: 3, value: 10, display: true },
    { source: 0, target: 4, value: 10, display: true },

    { source: 1, target: 3, value: 10, display: true },
    { source: 1, target: 4, value: 10, display: true },
      
    { source: 2, target: 3, value: 10, display: true },
    { source: 2, target: 4, value: 10, display: true },

    { source: 5, target: 6, value: 10, display: true },
    
    { source: 3, target: 6, value: 10, display: true },
    { source: 4, target: 6, value: 10, display: true },
     
  ]
};




var svg = d3.select("#netoworkGraphContainer").append("svg")
    .attr("width", width)
    .attr("height", height);

    function update(data) {


        var force = d3.layout.force()
                      .size([width, height])
                      .nodes(data.nodes)
                      .links(data.links)
                      .linkDistance(width/4);

        var links = svg.selectAll('.link')
            .data(data.links);

        links.enter()
             .append('line')
             .attr('class', 'link');

        var nodes = svg.selectAll(".node")
                      .data(data.nodes, function(d) { return d.name; }); //key fn
                      
        nodes.enter()
             .append("circle")
             .attr('class','node');

        //Set up tooltip
        var tip = d3.tip()
            .attr('class', 'd3-tip')
            .offset([-10, 0])
            .html(function (d) {
               return "<strong>" + d.name + "</strong><br/>" + d.size; //can be any html text if we want
            });
            svg.call(tip);

        nodes.on('mouseover', tip.show) 
             .on('mouseout', tip.hide); 

        force.on('tick', function() {

            nodes.attr({
                r: function(d) { return d.size; },
                cx: function(d) { return d.x; },
                cy: function(d) { return d.y; }
            });

            links.attr({
                x1: function(d) { return d.source.x; },
                y1: function(d) { return d.source.y; },
                x2: function(d) { return d.target.x; },
                y2: function(d) { return d.target.y; }
            });

        });

        force.start();

    }

    update(graphMLPData);


</script>
  

</body>

</html>